{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46e4f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIF                         T(K)   Fe    <Fe–N>(Å)     ζ(Å)     Σ(deg)     Θ(deg)     Vp(Å³)\n",
      "-----------------------------------------------------------------------------------------------\n",
      "M1_100k - Copy.cif           100    0       2.0490   0.5613     151.95      5.781     10.282\n",
      "M1_100k - Copy.cif           100    1       2.0490   0.5613     151.95      5.781     10.282\n",
      "M1_100k - Copy.cif           100    2       2.0490   0.5613     151.95      5.781     10.282\n",
      "M1_100k - Copy.cif           100    3       2.0490   0.5613     151.95      5.781     10.282\n",
      "M1_150K - Copy.cif           150    0       2.1236   0.2733     192.85     11.231     10.701\n",
      "M1_150K - Copy.cif           150    1       2.1236   0.2733     192.85     11.231     10.701\n",
      "M1_150K - Copy.cif           150    2       2.1236   0.2733     192.85     11.231     10.701\n",
      "M1_150K - Copy.cif           150    3       2.1236   0.2733     192.85     11.231     10.701\n",
      "M1_175K - Copy.cif           175    0       2.1199   0.2601     188.00      7.853     10.700\n",
      "M1_175K - Copy.cif           175    1       2.1199   0.2601     188.00      7.853     10.700\n",
      "M1_175K - Copy.cif           175    2       2.1199   0.2601     188.00      7.853     10.700\n",
      "M1_175K - Copy.cif           175    3       2.1199   0.2601     188.00      7.853     10.700\n",
      "M1_200k - Copy.cif           200    0       2.1532   0.4558     179.12      8.922     11.447\n",
      "M1_200k - Copy.cif           200    1       2.1532   0.4558     179.12      8.922     11.447\n",
      "M1_200k - Copy.cif           200    2       2.1532   0.4558     179.12      8.922     11.447\n",
      "M1_200k - Copy.cif           200    3       2.1532   0.4558     179.12      8.922     11.447\n",
      "M1_250k - Copy2.cif          250    0       2.1585   0.4585     179.13      8.998     11.529\n",
      "M1_250k - Copy2.cif          250    1       2.1585   0.4585     179.13      8.998     11.529\n",
      "M1_250k - Copy2.cif          250    2       2.1585   0.4585     179.13      8.998     11.529\n",
      "M1_250k - Copy2.cif          250    3       2.1585   0.4585     179.13      8.998     11.529\n",
      "M1_300k - Copy.cif           300    0       1.9945   0.8112     152.09      8.638      9.471\n",
      "M1_300k - Copy.cif           300    1       1.9945   0.8112     152.09      8.638      9.471\n",
      "M1_300k - Copy.cif           300    2       1.9945   0.8112     152.09      8.638      9.471\n",
      "M1_300k - Copy.cif           300    3       1.9945   0.8112     152.09      8.638      9.471\n",
      "M1_50k - Copy (1).cif         50    0       1.9945   0.4569     151.52      5.347      9.455\n",
      "M1_50k - Copy (1).cif         50    1       1.9945   0.4569     151.52      5.347      9.455\n",
      "M1_50k - Copy (1).cif         50    2       1.9945   0.4569     151.52      5.347      9.455\n",
      "M1_50k - Copy (1).cif         50    3       1.9945   0.4569     151.52      5.347      9.455\n",
      "M2_100K - Copy.cif           100    0       2.0101   0.2304     146.71     21.729      9.739\n",
      "M2_100K - Copy.cif           100    1       2.0101   0.2304     146.71     21.729      9.739\n",
      "M2_100K - Copy.cif           100    2       2.0101   0.2304     146.71     21.729      9.739\n",
      "M2_100K - Copy.cif           100    3       2.0101   0.2304     146.71     21.729      9.739\n",
      "M2_150K - Copy.cif           150    0       2.0109   0.2162     142.15     20.920      9.829\n",
      "M2_150K - Copy.cif           150    1       2.0109   0.2162     142.15     20.920      9.829\n",
      "M2_150K - Copy.cif           150    2       2.0109   0.2162     142.15     20.920      9.829\n",
      "M2_150K - Copy.cif           150    3       2.0109   0.2162     142.15     20.920      9.829\n",
      "M2_175K - Copy.cif           175    0       2.1206   0.4094     135.71     16.002     11.664\n",
      "M2_175K - Copy.cif           175    1       2.1206   0.4094     135.71     16.002     11.664\n",
      "M2_175K - Copy.cif           175    2       2.1206   0.4094     135.71     16.002     11.664\n",
      "M2_175K - Copy.cif           175    3       2.1206   0.4094     135.71     16.002     11.664\n",
      "M2_200K - Copy.cif           200    0       2.1648   0.6207     175.83     19.739     11.750\n",
      "M2_200K - Copy.cif           200    1       2.1648   0.6207     175.83     19.739     11.750\n",
      "M2_200K - Copy.cif           200    2       2.1648   0.6207     175.83     19.739     11.750\n",
      "M2_200K - Copy.cif           200    3       2.1648   0.6207     175.83     19.739     11.750\n",
      "M2_250K - Copy.cif           250    0       2.1588   0.5767     153.96     11.523     12.005\n",
      "M2_250K - Copy.cif           250    1       2.1588   0.5767     153.96     11.523     12.005\n",
      "M2_250K - Copy.cif           250    2       2.1588   0.5767     153.96     11.523     12.005\n",
      "M2_250K - Copy.cif           250    3       2.1588   0.5767     153.96     11.523     12.005\n",
      "M2_300K - Copy.cif           300    0       2.1662   0.5759     153.79     11.504     12.130\n",
      "M2_300K - Copy.cif           300    1       2.1662   0.5759     153.79     11.504     12.130\n",
      "M2_300K - Copy.cif           300    2       2.1662   0.5759     153.79     11.504     12.130\n",
      "M2_300K - Copy.cif           300    3       2.1662   0.5759     153.79     11.504     12.130\n",
      "M2_50K.cif                    50    0       2.0155   0.2695     195.99        nan      8.789\n",
      "M2_50K.cif                    50    1       2.0155   0.2695     195.99        nan      8.789\n",
      "M2_50K.cif                    50    2       2.0155   0.2695     195.99        nan      8.789\n",
      "M2_50K.cif                    50    3       2.0155   0.2695     195.99        nan      8.789\n",
      "\n",
      "✅ Analysis complete → FeN6_ColletGuionneau_distortion_vs_T.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna_msc/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/krishna_msc/.local/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import csv\n",
    "from itertools import combinations\n",
    "from math import acos, degrees\n",
    "from ase.io import read\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "# ============================================================\n",
    "# Silence harmless ASE CIF warnings\n",
    "# ============================================================\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"crystal system .* is not interpreted\"\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Geometry utilities\n",
    "# ============================================================\n",
    "\n",
    "def angle(v1, v2):\n",
    "    \"\"\"Angle (deg) between two vectors\"\"\"\n",
    "    cosang = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    cosang = np.clip(cosang, -1.0, 1.0)\n",
    "    return degrees(acos(cosang))\n",
    "\n",
    "# ============================================================\n",
    "# Core FeN6 analysis (Collet–Guionneau)\n",
    "# ============================================================\n",
    "\n",
    "def analyze_fe_site(atoms, fe_index):\n",
    "    \"\"\"\n",
    "    FeN6 distortion parameters:\n",
    "    <Fe–N>, zeta, Sigma, Theta (angular trigonal), Vp\n",
    "    \"\"\"\n",
    "\n",
    "    fe_pos = atoms[fe_index].position\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Collect Fe–N vectors\n",
    "    # --------------------------------------------------------\n",
    "    lig = []\n",
    "    for i, atom in enumerate(atoms):\n",
    "        if atom.symbol == \"N\":\n",
    "            vec = atoms.get_distance(fe_index, i, mic=True, vector=True)\n",
    "            dist = np.linalg.norm(vec)\n",
    "            lig.append((dist, vec))\n",
    "\n",
    "    if len(lig) < 6:\n",
    "        raise RuntimeError(f\"Fe index {fe_index}: fewer than 6 N atoms found\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Select 6 nearest N atoms\n",
    "    # --------------------------------------------------------\n",
    "    lig.sort(key=lambda x: x[0])\n",
    "    six = lig[:6]\n",
    "\n",
    "    bond_lengths = np.array([d for d, _ in six])\n",
    "    n_pos = np.array([fe_pos + vec for _, vec in six])\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1. Average Fe–N\n",
    "    # --------------------------------------------------------\n",
    "    avg_bond = bond_lengths.mean()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2. Bond-length distortion ζ\n",
    "    # --------------------------------------------------------\n",
    "    zeta = bond_lengths.max() - bond_lengths.min()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3. Angular distortion Σ\n",
    "    # --------------------------------------------------------\n",
    "    angles = []\n",
    "    for i, j in combinations(range(6), 2):\n",
    "        v1 = n_pos[i] - fe_pos\n",
    "        v2 = n_pos[j] - fe_pos\n",
    "        angles.append(angle(v1, v2))\n",
    "\n",
    "    angles.sort()\n",
    "    cis_angles = angles[:12]  # remove 3 trans angles\n",
    "    Sigma = sum(abs(a - 90.0) for a in cis_angles)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 4. Trigonal angular distortion Θ\n",
    "    #    (robust face-based definition)\n",
    "    # --------------------------------------------------------\n",
    "    u = []\n",
    "    for pos in n_pos:\n",
    "        v = pos - fe_pos\n",
    "        u.append(v / np.linalg.norm(v))\n",
    "    u = np.array(u)\n",
    "\n",
    "    face_alphas = []\n",
    "\n",
    "    for i, j, k in combinations(range(6), 3):\n",
    "\n",
    "        a_ij = angle(u[i], u[j])\n",
    "        a_jk = angle(u[j], u[k])\n",
    "        a_ki = angle(u[k], u[i])\n",
    "\n",
    "        # trigonal faces = all cis\n",
    "        if (\n",
    "            70.0 < a_ij < 110.0 and\n",
    "            70.0 < a_jk < 110.0 and\n",
    "            70.0 < a_ki < 110.0\n",
    "        ):\n",
    "            alpha = 180.0 - 0.5 * (a_ij + a_jk + a_ki)\n",
    "            face_alphas.append(alpha)\n",
    "\n",
    "    #if len(face_alphas) < 4:\n",
    "        #print(\n",
    "            #f\"⚠️ Warning: Fe index {fe_index} – \"\n",
    "            #f\"only {len(face_alphas)} trigonal faces detected\"\n",
    "        #)\n",
    "\n",
    "    Theta = np.mean([abs(a - 60.0) for a in face_alphas])\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 5. Polyhedral volume Vp\n",
    "    # --------------------------------------------------------\n",
    "    hull = ConvexHull(n_pos)\n",
    "    Vp = hull.volume\n",
    "\n",
    "    return avg_bond, zeta, Sigma, Theta, Vp\n",
    "\n",
    "# ============================================================\n",
    "# Batch processing + table output\n",
    "# ============================================================\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\n",
    "    f\"{'CIF':25s} {'T(K)':>6s} {'Fe':>4s} \"\n",
    "    f\"{'<Fe–N>(Å)':>12s} {'ζ(Å)':>8s} \"\n",
    "    f\"{'Σ(deg)':>10s} {'Θ(deg)':>10s} {'Vp(Å³)':>10s}\"\n",
    ")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "for cif in sorted(glob.glob(\"*.cif\")):\n",
    "\n",
    "    atoms = read(cif)\n",
    "\n",
    "    temp_match = re.search(r\"(\\d+)\\s*[Kk]\", cif)\n",
    "    temperature = int(temp_match.group(1)) if temp_match else None\n",
    "\n",
    "    for i, atom in enumerate(atoms):\n",
    "        if atom.symbol == \"Fe\":\n",
    "\n",
    "            avg_bond, zeta, Sigma, Theta, Vp = analyze_fe_site(atoms, i)\n",
    "\n",
    "            print(\n",
    "                f\"{cif:25s} \"\n",
    "                f\"{str(temperature) if temperature else 'NA':>6s} \"\n",
    "                f\"{i:4d} \"\n",
    "                f\"{avg_bond:12.4f} \"\n",
    "                f\"{zeta:8.4f} \"\n",
    "                f\"{Sigma:10.2f} \"\n",
    "                f\"{Theta:10.3f} \"\n",
    "                f\"{Vp:10.3f}\"\n",
    "            )\n",
    "\n",
    "            results.append([\n",
    "                cif,\n",
    "                temperature,\n",
    "                i,\n",
    "                avg_bond,\n",
    "                zeta,\n",
    "                Sigma,\n",
    "                Theta,\n",
    "                Vp\n",
    "            ])\n",
    "\n",
    "# ============================================================\n",
    "# Save CSV\n",
    "# ============================================================\n",
    "\n",
    "with open(\"FeN6_ColletGuionneau_distortion_vs_T.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\n",
    "        \"CIF\",\n",
    "        \"Temperature (K)\",\n",
    "        \"Fe_index\",\n",
    "        \"<Fe–N> (Å)\",\n",
    "        \"zeta (Å)\",\n",
    "        \"Sigma (deg)\",\n",
    "        \"Theta (deg)\",\n",
    "        \"Vp (Å^3)\"\n",
    "    ])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(\"\\n✅ Analysis complete → FeN6_ColletGuionneau_distortion_vs_T.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b173d333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sites found: HS=204  LS=204\n",
      "\n",
      "=== RESULTS ===\n",
      "Number of atoms compared: 204\n",
      "Average RMSD (Å): 0.2686\n",
      "Maximum deviation (Å): 1.1400  (matched atom index: 27, element: S)\n",
      "Wrote per-atom text -> rmsd_out_per_atom.txt\n",
      "Wrote per-atom CSV  -> rmsd_out_per_atom.csv\n",
      "Wrote overlay CIF for VESTA -> rmsd_out_overlay.cif\n",
      "In VESTA, open the CIF, go to Edit->Atoms and check atom labels (they contain _LS, _HS, and _MAX_HS).\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "rmsd_asu_match.py\n",
    "\n",
    "Reads two CIFs (HS and LS), extracts the asymmetric unit (unique positions\n",
    "from the CIF), matches atoms by element with an optimal assignment,\n",
    "applies periodic minimum-image convention, aligns HS->LS (Kabsch),\n",
    "computes per-atom displacements, prints Average RMSD and Max deviation,\n",
    "writes per-atom CSV/text outputs and a combined CIF for VESTA with labels.\n",
    "\n",
    "Requirements:\n",
    "  - ase\n",
    "  - numpy\n",
    "  - scipy (optional but recommended; if missing the script falls back to greedy matching)\n",
    "\n",
    "Usage:\n",
    "  - edit the hs_file and ls_file below or pass them via command line (quick edit)\n",
    "  - python rmsd_asu_match.py\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from ase.io import read, write\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Try to import Hungarian assignment\n",
    "try:\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    SCIPY_AVAILABLE = True\n",
    "except Exception:\n",
    "    SCIPY_AVAILABLE = False\n",
    "\n",
    "# ----------------- USER INPUT -----------------\n",
    "hs_file = \"M2_300K - Copy.cif\"   # high-spin CIF\n",
    "ls_file = \"M2_100K - Copy.cif\"          # low-spin CIF\n",
    "use_only_heavy_atoms = False     # ignore H? (True/False)\n",
    "out_prefix = \"rmsd_out\"          # output files prefix\n",
    "uniqueness_tol = 1e-3           # tolerance in fractional coords to deduplicate\n",
    "# ------------------------------------------------\n",
    "\n",
    "def get_asymmetric_unit(atoms, tol=1e-3, keep_H=True):\n",
    "    \"\"\"\n",
    "    Return (symbols_frac, frac_positions, cart_positions, original_indices)\n",
    "    representing a deduplicated (unique) set of atomic sites from the CIF by\n",
    "    grouping positions that are identical modulo lattice translations.\n",
    "    This approximates the asymmetric unit if the CIF contains symmetry-expanded atoms.\n",
    "    \"\"\"\n",
    "    frac = atoms.get_scaled_positions(wrap=True)\n",
    "    cart = atoms.get_positions()\n",
    "    syms = np.array(atoms.get_chemical_symbols())\n",
    "    keep_mask = np.ones(len(syms), dtype=bool)\n",
    "    if not keep_H:\n",
    "        keep_mask = (atoms.get_atomic_numbers() > 1)\n",
    "    frac = frac[keep_mask]\n",
    "    cart = cart[keep_mask]\n",
    "    syms = syms[keep_mask]\n",
    "\n",
    "    unique_syms = []\n",
    "    unique_frac = []\n",
    "    unique_cart = []\n",
    "    unique_orig_idx = []\n",
    "\n",
    "    def frac_dist(a, b):\n",
    "        # minimum-image distance in fractional coordinates\n",
    "        d = a - b\n",
    "        d = d - np.round(d)  # put into -0.5..0.5\n",
    "        return np.linalg.norm(d)\n",
    "\n",
    "    for i, (f, c, s) in enumerate(zip(frac, cart, syms)):\n",
    "        found = False\n",
    "        for j, uf in enumerate(unique_frac):\n",
    "            if s != unique_syms[j]:\n",
    "                # only combine same element; different elements can have very close coords in some cases\n",
    "                continue\n",
    "            if frac_dist(f, uf) < tol:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            unique_syms.append(s)\n",
    "            unique_frac.append(f.copy())\n",
    "            unique_cart.append(c.copy())\n",
    "            unique_orig_idx.append(i)\n",
    "    # convert lists to arrays\n",
    "    unique_frac = np.array(unique_frac)\n",
    "    unique_cart = np.array(unique_cart)\n",
    "    unique_syms = np.array(unique_syms)\n",
    "    return unique_syms, unique_frac, unique_cart, unique_orig_idx\n",
    "\n",
    "def frac_to_cart(frac, cell):\n",
    "    \"\"\"Convert Nx3 fractional coords to Cartesian using cell (3x3 array).\"\"\"\n",
    "    # cart = frac @ cell\n",
    "    return np.dot(frac, cell)\n",
    "\n",
    "def minimum_image_frac_delta(p_frac, q_frac):\n",
    "    \"\"\"Return fractional delta vector with minimum image (range -0.5..+0.5).\"\"\"\n",
    "    d = p_frac - q_frac\n",
    "    d = d - np.round(d)\n",
    "    return d\n",
    "\n",
    "def kabsch(P, Q):\n",
    "    \"\"\"Return rotation matrix R that aligns P -> Q (both centered).\"\"\"\n",
    "    H = P.T @ Q\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R = Vt.T @ U.T\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = Vt.T @ U.T\n",
    "    return R\n",
    "\n",
    "def match_atoms_by_element_and_distance(symA, fracA, symB, fracB, cell, use_scipy=True):\n",
    "    \"\"\"\n",
    "    Return index arrays (idxA, idxB) such that symA[idxA[k]] matches symB[idxB[k]].\n",
    "    Matching is per-element and solves minimal total Cartesian distances using Hungarian algorithm.\n",
    "    Fallback: greedy nearest-neighbour per element if scipy not available.\n",
    "    \"\"\"\n",
    "    if len(symA) != len(symB):\n",
    "        raise ValueError(\"Different numbers of unique atoms: {} vs {}\".format(len(symA), len(symB)))\n",
    "\n",
    "    N = len(symA)\n",
    "    idxA_final = []\n",
    "    idxB_final = []\n",
    "\n",
    "    elements = sorted(set(symA))\n",
    "    for el in elements:\n",
    "        # indices of element el in both lists\n",
    "        ia = [i for i,s in enumerate(symA) if s == el]\n",
    "        ib = [i for i,s in enumerate(symB) if s == el]\n",
    "        if len(ia) != len(ib):\n",
    "            # can't do perfect element-wise matching -> try to proceed but warn\n",
    "            print(f\"Warning: element counts differ for {el}: {len(ia)} vs {len(ib)}. Will attempt global matching.\")\n",
    "            # fallback to global matching\n",
    "            return match_atoms_globally(symA, fracA, symB, fracB, cell, use_scipy)\n",
    "        na = len(ia)\n",
    "        if na == 0:\n",
    "            continue\n",
    "        # build cost matrix (Cartesian distances using minimum-image)\n",
    "        cost = np.zeros((na, na))\n",
    "        for ii, aidx in enumerate(ia):\n",
    "            for jj, bidx in enumerate(ib):\n",
    "                df = minimum_image_frac_delta(fracA[aidx], fracB[bidx])\n",
    "                dcart = frac_to_cart(df, cell)\n",
    "                cost[ii, jj] = np.linalg.norm(dcart)\n",
    "        if use_scipy and SCIPY_AVAILABLE:\n",
    "            row, col = linear_sum_assignment(cost)\n",
    "        else:\n",
    "            # greedy fallback: assign each row to nearest unassigned column\n",
    "            row = []\n",
    "            col = []\n",
    "            available = set(range(na))\n",
    "            for ii in range(na):\n",
    "                # find nearest available column\n",
    "                nearest_j = min(available, key=lambda j: cost[ii, j])\n",
    "                row.append(ii)\n",
    "                col.append(nearest_j)\n",
    "                available.remove(nearest_j)\n",
    "        # map back to original indices\n",
    "        for r, c in zip(row, col):\n",
    "            idxA_final.append(ia[r])\n",
    "            idxB_final.append(ib[c])\n",
    "    # Return index arrays in order of idxA_final\n",
    "    # sort by idxA_final to have stable ordering\n",
    "    order = np.argsort(idxA_final)\n",
    "    idxA_final = [idxA_final[i] for i in order]\n",
    "    idxB_final = [idxB_final[i] for i in order]\n",
    "    return np.array(idxA_final, dtype=int), np.array(idxB_final, dtype=int)\n",
    "\n",
    "def match_atoms_globally(symA, fracA, symB, fracB, cell, use_scipy=True):\n",
    "    \"\"\"\n",
    "    If per-element counts don't match, do a global assignment minimizing distances\n",
    "    but penalize element mismatch heavily.\n",
    "    \"\"\"\n",
    "    N = len(symA)\n",
    "    cost = np.zeros((N, N))\n",
    "    big_penalty = 1e3\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            el_pen = 0 if symA[i] == symB[j] else big_penalty\n",
    "            df = minimum_image_frac_delta(fracA[i], fracB[j])\n",
    "            dcart = frac_to_cart(df, cell)\n",
    "            cost[i, j] = np.linalg.norm(dcart) + el_pen\n",
    "    if use_scipy and SCIPY_AVAILABLE:\n",
    "        row, col = linear_sum_assignment(cost)\n",
    "    else:\n",
    "        # greedy fallback\n",
    "        row = []\n",
    "        col = []\n",
    "        available = set(range(N))\n",
    "        for i in range(N):\n",
    "            nearest_j = min(available, key=lambda j: cost[i, j])\n",
    "            row.append(i)\n",
    "            col.append(nearest_j)\n",
    "            available.remove(nearest_j)\n",
    "    order = np.argsort(row)\n",
    "    return np.array(row)[order], np.array(col)[order]\n",
    "\n",
    "def main():\n",
    "    # 1) Read CIFs\n",
    "    if not os.path.exists(hs_file):\n",
    "        print(\"HS file not found:\", hs_file); sys.exit(1)\n",
    "    if not os.path.exists(ls_file):\n",
    "        print(\"LS file not found:\", ls_file); sys.exit(1)\n",
    "\n",
    "    hs_atoms = read(hs_file)\n",
    "    ls_atoms = read(ls_file)\n",
    "\n",
    "    if use_only_heavy_atoms:\n",
    "        print(\"NOTE: hydrogens will be excluded from asymmetric-unit extraction and matching.\")\n",
    "\n",
    "    # 2) Extract asymmetric unit candidates\n",
    "    syms_hs, frac_hs, cart_hs, idx_hs = get_asymmetric_unit(hs_atoms, tol=uniqueness_tol, keep_H=not use_only_heavy_atoms)\n",
    "    syms_ls, frac_ls, cart_ls, idx_ls = get_asymmetric_unit(ls_atoms, tol=uniqueness_tol, keep_H=not use_only_heavy_atoms)\n",
    "\n",
    "    print(f\"Unique sites found: HS={len(syms_hs)}  LS={len(syms_ls)}\")\n",
    "    if len(syms_hs) != len(syms_ls):\n",
    "        print(\"Warning: number of unique sites differs. Will still attempt global matching.\")\n",
    "\n",
    "    # Use LS cell for Cartesian conversions & as reference\n",
    "    cell = np.array(ls_atoms.get_cell())\n",
    "    # 3) Match atoms (indices arrays)\n",
    "    try:\n",
    "        ia, ib = match_atoms_by_element_and_distance(syms_hs, frac_hs, syms_ls, frac_ls, cell, use_scipy=True)\n",
    "    except Exception as e:\n",
    "        print(\"Error during per-element matching:\", e)\n",
    "        print(\"Falling back to global matching.\")\n",
    "        ia, ib = match_atoms_globally(syms_hs, frac_hs, syms_ls, frac_ls, cell, use_scipy=True)\n",
    "\n",
    "    # reorder arrays to matched order\n",
    "    syms_hs_matched = syms_hs[ia]\n",
    "    syms_ls_matched = syms_ls[ib]\n",
    "    frac_hs_matched = frac_hs[ia]\n",
    "    frac_ls_matched = frac_ls[ib]\n",
    "\n",
    "    # convert fractional to Cartesian in LS cell (apply minimum-image for matches)\n",
    "    cart_ls_matched = frac_to_cart(frac_ls_matched, cell)\n",
    "    # For HS we compute delta fractional (min image) relative to matched LS and convert to cart\n",
    "    cart_hs_matched = np.zeros_like(cart_ls_matched)\n",
    "    for k in range(len(frac_hs_matched)):\n",
    "        df = minimum_image_frac_delta(frac_hs_matched[k], frac_ls_matched[k])\n",
    "        cart_hs_matched[k] = frac_to_cart(frac_ls_matched[k] + df, cell)  # effectively aligned in same cell\n",
    "\n",
    "    # 4) Center and apply Kabsch: align HS -> LS\n",
    "    P = cart_hs_matched.copy()\n",
    "    Q = cart_ls_matched.copy()\n",
    "    P_cent = P - P.mean(axis=0)\n",
    "    Q_cent = Q - Q.mean(axis=0)\n",
    "    R = kabsch(P_cent, Q_cent)\n",
    "    P_aligned = (P_cent @ R)  # still centered like Q_cent\n",
    "    # position HS aligned into LS frame by shifting to Q mean:\n",
    "    P_aligned_cart = P_aligned + Q.mean(axis=0)\n",
    "\n",
    "    # compute per-atom deviation vectors and distances\n",
    "    dvecs = P_aligned_cart - Q\n",
    "    dists = np.linalg.norm(dvecs, axis=1)\n",
    "    avg_rmsd = math.sqrt(np.mean(dists**2))\n",
    "    max_dev = float(np.max(dists))\n",
    "    max_idx = int(np.argmax(dists))  # index in matched arrays\n",
    "    print(\"\\n=== RESULTS ===\")\n",
    "    print(f\"Number of atoms compared: {len(dists)}\")\n",
    "    print(f\"Average RMSD (Å): {avg_rmsd:.4f}\")\n",
    "    print(f\"Maximum deviation (Å): {max_dev:.4f}  (matched atom index: {max_idx}, element: {syms_hs_matched[max_idx]})\")\n",
    "\n",
    "    # 5) Write outputs\n",
    "    txt_out = out_prefix + \"_per_atom.txt\"\n",
    "    csv_out = out_prefix + \"_per_atom.csv\"\n",
    "    cif_out = out_prefix + \"_overlay.cif\"\n",
    "\n",
    "    with open(txt_out, \"w\") as f:\n",
    "        f.write(\"# idx  elem  HS_frac_x HS_frac_y HS_frac_z   HS_cart_x HS_cart_y HS_cart_z   \"\n",
    "                \"LS_frac_x LS_frac_y LS_frac_z   LS_cart_x LS_cart_y LS_cart_z   disp_A\\n\")\n",
    "        for i, (s, hf, hc, lf, lc, dist) in enumerate(zip(syms_hs_matched, frac_hs_matched, P_aligned_cart,\n",
    "                                                        frac_ls_matched, cart_ls_matched, dists), start=1):\n",
    "            f.write(f\"{i:3d} {s:>2s}  \"\n",
    "                    f\"{hf[0]:8.5f} {hf[1]:8.5f} {hf[2]:8.5f}  \"\n",
    "                    f\"{hc[0]:10.5f} {hc[1]:10.5f} {hc[2]:10.5f}  \"\n",
    "                    f\"{lf[0]:8.5f} {lf[1]:8.5f} {lf[2]:8.5f}  \"\n",
    "                    f\"{lc[0]:10.5f} {lc[1]:10.5f} {lc[2]:10.5f}  \"\n",
    "                    f\"{dist:8.5f}\\n\")\n",
    "    # CSV\n",
    "    with open(csv_out, \"w\") as f:\n",
    "        f.write(\"idx,elem,HS_frac_x,HS_frac_y,HS_frac_z,HS_cart_x,HS_cart_y,HS_cart_z,\"\n",
    "                \"LS_frac_x,LS_frac_y,LS_frac_z,LS_cart_x,LS_cart_y,LS_cart_z,disp_A\\n\")\n",
    "        for i, (s, hf, hc, lf, lc, dist) in enumerate(zip(syms_hs_matched, frac_hs_matched, P_aligned_cart,\n",
    "                                                        frac_ls_matched, cart_ls_matched, dists), start=1):\n",
    "            f.write(f\"{i},{s},{hf[0]:.6f},{hf[1]:.6f},{hf[2]:.6f},\"\n",
    "                    f\"{hc[0]:.6f},{hc[1]:.6f},{hc[2]:.6f},\"\n",
    "                    f\"{lf[0]:.6f},{lf[1]:.6f},{lf[2]:.6f},\"\n",
    "                    f\"{lc[0]:.6f},{lc[1]:.6f},{lc[2]:.6f},{dist:.6f}\\n\")\n",
    "\n",
    "    print(f\"Wrote per-atom text -> {txt_out}\")\n",
    "    print(f\"Wrote per-atom CSV  -> {csv_out}\")\n",
    "\n",
    "    # 6) Create overlay CIF for VESTA:\n",
    "    # We'll create a combined Atoms object: LS atoms (normal labels) + HS aligned atoms (labels include _HS, and the max gets _MAX)\n",
    "    # Use original LS atoms positions for LS block, and use P_aligned_cart for HS block.\n",
    "    ls_copy = ls_atoms.copy()\n",
    "    hs_copy = ls_atoms.copy()  # create a copy to get right cell / arrays; we'll overwrite positions & symbols for HS block\n",
    "\n",
    "    # We'll build new atoms object manually using ase.Atoms concatenation\n",
    "    from ase import Atoms\n",
    "    # Get LS atoms in the same order as matched list (ls matched indices ib)\n",
    "    # But we earlier had idx_ls original mapping; ib indices refer to unique list indices.\n",
    "    # We'll extract positions and symbols for the matched LS unique sites.\n",
    "    ls_syms_matched = syms_ls_matched\n",
    "    ls_cart_matched = cart_ls_matched\n",
    "\n",
    "    # Build LS atoms (ordered)\n",
    "    atoms_ls_ordered = Atoms(symbols=list(ls_syms_matched), positions=list(ls_cart_matched), cell=cell, pbc=True)\n",
    "\n",
    "    # Build HS atoms (aligned positions -> P_aligned_cart)\n",
    "    hs_syms_ordered = syms_hs_matched.copy()\n",
    "    hs_symbols_for_cif = []\n",
    "    for i, sym in enumerate(hs_syms_ordered):\n",
    "        lab = sym + \"_HS\"\n",
    "        if i == max_idx:\n",
    "            lab = sym + \"_MAX_HS\"\n",
    "        hs_symbols_for_cif.append(sym)  # keep actual chemical symbol (ASE expects real elements)\n",
    "\n",
    "    atoms_hs_ordered = Atoms(symbols=list(hs_syms_ordered), positions=list(P_aligned_cart), cell=cell, pbc=True)\n",
    "\n",
    "    # Attach labels arrays so CIF writer puts them into _atom_site_label\n",
    "    labels_ls = [f\"{sym}_LS\" for sym in ls_syms_matched]\n",
    "    labels_hs = []\n",
    "    for i, sym in enumerate(hs_syms_ordered):\n",
    "        if i == max_idx:\n",
    "            labels_hs.append(f\"{sym}_MAX_HS\")\n",
    "        else:\n",
    "            labels_hs.append(f\"{sym}_HS\")\n",
    "    atoms_ls_ordered.new_array(\"labels\", np.array(labels_ls, dtype=object))\n",
    "    atoms_hs_ordered.new_array(\"labels\", np.array(labels_hs, dtype=object))\n",
    "\n",
    "    combined = atoms_ls_ordered + atoms_hs_ordered\n",
    "    combined.set_cell(cell)\n",
    "    combined.wrap()\n",
    "\n",
    "    write(cif_out, combined)\n",
    "    print(f\"Wrote overlay CIF for VESTA -> {cif_out}\")\n",
    "    print(\"In VESTA, open the CIF, go to Edit->Atoms and check atom labels (they contain _LS, _HS, and _MAX_HS).\")\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326039e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
